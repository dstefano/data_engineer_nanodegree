{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# US National Tourism and Trade Office - Data Engineering\n",
    "### Data Engineering 2020 -  Capstone Project\n",
    "\n",
    "#### Author: Priscila De-Stefano\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "The main goal of this project is to organize data from US National Tourism and Trade Office in order to create a data lake and a structured database.\n",
    "\n",
    "The project follows the following sections:\n",
    "* Project Scope\n",
    "* Gather Data\n",
    "* Data Explore\n",
    "* Data Model\n",
    "* Data Pipeline\n",
    "* Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Project Scope\n",
    "\n",
    "The main goal of this project is to organize data from United States immigration in order to create a data lake and a structured database. This two environments could be used by third-party softwares in other to gather detailed information about the flow of people in and out of the United States in the year of 2016.\n",
    "\n",
    "Example of data that could be retrived from this environment:\n",
    "* number of non-immigrants arriving in the US by state in 2016\n",
    "* number of non-immigrants arriving in the US by city in 2016\n",
    "* number of non-immigrants arriving in the US for Education purposes in 2016\n",
    "* number of non-immigrants arriving in the US for Business purposes in 2016\n",
    "* ranking of states that receive more students in the US\n",
    "* ranking of airports that most receive people from a given country\n",
    "* etc...\n",
    "\n",
    "\n",
    "#### Data Lake - AWS S3\n",
    "\n",
    "Data is load from data sources into Dataframes. After data is organized, verified and cleaned, it is saved in a AWS S3 enviroment.\n",
    "The S3 bucket contains csv files and parquet files.\n",
    "\n",
    "#### Database - AWS Redshift\n",
    "\n",
    "This final database is implemented on AWS Redshift. Data is loaded from Data Lake by tasks on Apache Airflow and then saved in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Gather Data\n",
    "\n",
    "This project is based on three data sources:\n",
    "* **Immigration Data**: This data comes from US National Tourism and Trade Office and is the biggest data set of this project. For the scope of this project submission, only data from April 2016 is being used.\n",
    "* **Aiports data source**: This data comes from DataHub.com and it describes basic information about airports around the world\n",
    "* **Immigration data dictionary**: This data source is provided by Udacity team and being used to better describe and clean data\n",
    "\n",
    "The steps below describe how data is being gathered and saved into Pandas Dataframes and a Spark Dataframe.\n",
    "\n",
    "### IMPORTANT:\n",
    "Package s3fs must be installed in this enviroment in order to run this notebook properly.\n",
    "<br>\n",
    "**command**: pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import configparser\n",
    "from pyspark.sql.types import IntegerType\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get AWS credentials\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# DATA SOURCE: US National Tourism and Trade Office.\n",
    "df_immig_sample = pd.read_csv(\"immigration_data_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# DATA SOURCE: COUNTRY CODES FROM DATA DICTIONARY\n",
    "df_country = pd.read_csv(\"country_code.csv\",delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# DATA SOURCE: ENTRY PORT CODES FROM DATA DICTIONARY\n",
    "df_port = pd.read_csv(\"entry_port_code.csv\",delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# DATA SOURCE: TRAVEL MODE CODES FROM DATA DICTIONARY\n",
    "df_mode = pd.read_csv(\"travel_mode.csv\",delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# DATA SOURCE: STATE CODES FROM DATA DICTIONARY\n",
    "df_state = pd.read_csv(\"state.csv\",delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# DATA SOURCE: VISA CODES FROM DATA DICTIONARY\n",
    "df_visa = pd.read_csv(\"visa.csv\",delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# DATA SOURCE: STATE CODES FROM DATA DICTIONARY\n",
    "df_state = pd.read_csv(\"state.csv\",delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# DATA SOURCE: Airport Codes from DataHub\n",
    "df_airport = pd.read_csv(\"airport-codes_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# source for property names:\n",
    "# https://hadoop.apache.org/docs/current3/hadoop-aws/tools/hadoop-aws/#Authentication_properties\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11,org.apache.hadoop:hadoop-aws:2.7.2\").\\\n",
    "config(\"fs.s3a.access.key\", os.environ['AWS_ACCESS_KEY_ID']).\\\n",
    "config(\"fs.s3a.secret.key\", os.environ['AWS_SECRET_ACCESS_KEY'])\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto  gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016       F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016       M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016       M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016       M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016       F   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658267e+10  00782        WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immig_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>'MEXICO Air Sea, and Not Reported (I-94, no ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>'AFGHANISTAN'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>'ALBANIA'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>'ALGERIA'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>'ANDORRA'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code                                        description\n",
       "0   582    'MEXICO Air Sea, and Not Reported (I-94, no ...\n",
       "1   236                                      'AFGHANISTAN'\n",
       "2   101                                          'ALBANIA'\n",
       "3   316                                          'ALGERIA'\n",
       "4   102                                          'ANDORRA'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_country.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'AL'</td>\n",
       "      <td>'ALABAMA'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'AK'</td>\n",
       "      <td>'ALASKA'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'AZ'</td>\n",
       "      <td>'ARIZONA'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'AR'</td>\n",
       "      <td>'ARKANSAS'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'CA'</td>\n",
       "      <td>'CALIFORNIA'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code   description\n",
       "0  'AL'     'ALABAMA'\n",
       "1  'AK'      'ALASKA'\n",
       "2  'AZ'     'ARIZONA'\n",
       "3  'AR'    'ARKANSAS'\n",
       "4  'CA'  'CALIFORNIA'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_state.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'ALC'\\t</td>\n",
       "      <td>\\t'ALCAN, AK             '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'ANC'\\t</td>\n",
       "      <td>\\t'ANCHORAGE, AK         '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'BAR'\\t</td>\n",
       "      <td>\\t'BAKER AAF - BAKER ISLAND, AK'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'DAC'\\t</td>\n",
       "      <td>\\t'DALTONS CACHE, AK     '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'PIZ'\\t</td>\n",
       "      <td>\\t'DEW STATION PT LAY DEW, AK'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         code                       description\n",
       "0     'ALC'\\t        \\t'ALCAN, AK             '\n",
       "1     'ANC'\\t        \\t'ANCHORAGE, AK         '\n",
       "2     'BAR'\\t  \\t'BAKER AAF - BAKER ISLAND, AK'\n",
       "3     'DAC'\\t        \\t'DALTONS CACHE, AK     '\n",
       "4     'PIZ'\\t    \\t'DEW STATION PT LAY DEW, AK'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>'Air'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>'Sea'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>'Land'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>'Not reported'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code      description\n",
       "0     1            'Air'\n",
       "1     2            'Sea'\n",
       "2     3           'Land'\n",
       "3     9   'Not reported'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mode.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code description\n",
       "0     1    Business\n",
       "1     2    Pleasure\n",
       "2     3     Student"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visa.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Explore\n",
    "In this section data will be explored in order to find missing values, duplicate data, etc.\n",
    "Also, some columns are renamed in order to improve the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove \\t and \\n from data dictionary dataframes\n",
    "df_country = df_country.replace('(\\t|\\n)','', regex=True)\n",
    "df_mode = df_mode.replace('(\\t|\\n)','', regex=True)\n",
    "df_state = df_state.replace('(\\t|\\n)','', regex=True)\n",
    "df_visa = df_visa.replace('(\\t|\\n)','', regex=True)\n",
    "df_port = df_port.replace('(\\t|\\n)','', regex=True)\n",
    "df_state = df_state.replace('(\\t|\\n)','', regex=True)\n",
    "\n",
    "\n",
    "# remove '' from data dictionary dataframes\n",
    "df_country['description'] = df_country['description'].map(lambda x: x.lstrip(' \\'').rstrip('\\''))\n",
    "df_port['code'] = df_port['code'].map(lambda x: x.lstrip(' \\'').rstrip('\\''))\n",
    "df_port['description'] = df_port['description'].map(lambda x: x.lstrip(' \\'').rstrip('\\''))\n",
    "df_mode['description'] = df_mode['description'].map(lambda x: x.lstrip(' \\'').rstrip('\\''))\n",
    "df_state['description'] = df_state['description'].map(lambda x: x.lstrip(' \\'').rstrip('\\''))\n",
    "df_visa['description'] = df_visa['description'].map(lambda x: x.lstrip(' \\'').rstrip('\\''))\n",
    "df_state['code'] = df_state['code'].map(lambda x: x.lstrip(' \\'').rstrip('\\''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# drop columns that won't be used during project\n",
    "columns = ['count', 'visapost','i94cit','biryear', 'insnum','dtaddto','dtadfile', 'matflag', 'entdepa', \n",
    "           'entdepd', 'entdepu', 'occup', 'airline', 'fltno', 'adm_num']\n",
    "df_spark = df_spark.drop(*columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cic_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>country_code</th>\n",
       "      <th>us_entry_port</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>travel_mode</th>\n",
       "      <th>us_state</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>age</th>\n",
       "      <th>visa_code</th>\n",
       "      <th>gender</th>\n",
       "      <th>adm_num</th>\n",
       "      <th>visa_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cic_id    year  month  country_code us_entry_port  arrival_date  \\\n",
       "0     6.0  2016.0    4.0         692.0           XXX       20573.0   \n",
       "\n",
       "  travel_mode us_state departure_date   age  visa_code gender       adm_num  \\\n",
       "0        None     None           None  37.0        2.0   None  1.897628e+09   \n",
       "\n",
       "  visa_type  \n",
       "0        B2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# renaming columns\n",
    "df_spark = df_spark.withColumnRenamed(\"cicid\",\"cic_id\") \\\n",
    "    .withColumnRenamed(\"i94yr\",\"year\") \\\n",
    "    .withColumnRenamed(\"i94mon\",\"month\") \\\n",
    "    .withColumnRenamed(\"i94res\",\"country_code\") \\\n",
    "    .withColumnRenamed(\"i94port\",\"us_entry_port\") \\\n",
    "    .withColumnRenamed(\"arrdate\",\"arrival_date\") \\\n",
    "    .withColumnRenamed(\"i94mode\",\"travel_mode\") \\\n",
    "    .withColumnRenamed(\"i94addr\",\"us_state\") \\\n",
    "    .withColumnRenamed(\"depdate\",\"departure_date\") \\\n",
    "    .withColumnRenamed(\"i94bir\",\"age\") \\\n",
    "    .withColumnRenamed(\"i94visa\",\"visa_code\") \\\n",
    "    .withColumnRenamed(\"visatype\",\"visa_type\") \\\n",
    "    .withColumnRenamed(\"biryear\",\"birth_year\") \\\n",
    "    .withColumnRenamed(\"admnum\",\"adm_num\") \\\n",
    "\n",
    "df_spark.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clean by column us_state: remove rows which us_state is not valid\n",
    "df_state_array =  list(df_state['code'])\n",
    "df_spark = df_spark.filter(df_spark.us_state.isin(*df_state_array) == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def convert_datetime(x):\n",
    "    try:\n",
    "        start = datetime(1960, 1, 1)\n",
    "        return start + timedelta(days=int(x))\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "udf_datetime_from_sas = udf(lambda x: convert_datetime(x), T.DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cic_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>country_code</th>\n",
       "      <th>us_entry_port</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>travel_mode</th>\n",
       "      <th>us_state</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>age</th>\n",
       "      <th>visa_code</th>\n",
       "      <th>gender</th>\n",
       "      <th>adm_num</th>\n",
       "      <th>visa_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>276</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>2147483647</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cic_id  year  month  country_code us_entry_port arrival_date  travel_mode  \\\n",
       "0       7  2016      4           276           ATL   2016-04-07            1   \n",
       "\n",
       "  us_state departure_date  age  visa_code gender     adm_num visa_type  \n",
       "0       AL           None   25          3      M  2147483647        F1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert text columns to integer in spark dataframe\n",
    "df_spark = df_spark.withColumn(\"year\", df_spark[\"year\"].cast(IntegerType()))\n",
    "df_spark = df_spark.withColumn(\"month\", df_spark[\"month\"].cast(IntegerType()))\n",
    "df_spark = df_spark.withColumn(\"cic_id\", df_spark[\"cic_id\"].cast(IntegerType()))\n",
    "df_spark = df_spark.withColumn(\"country_code\", df_spark[\"country_code\"].cast(IntegerType()))\n",
    "df_spark = df_spark.withColumn(\"arrival_date\", df_spark[\"arrival_date\"].cast(IntegerType()))\n",
    "df_spark = df_spark.withColumn(\"departure_date\", df_spark[\"departure_date\"].cast(IntegerType()))\n",
    "df_spark = df_spark.withColumn(\"travel_mode\", df_spark[\"travel_mode\"].cast(IntegerType()))\n",
    "df_spark = df_spark.withColumn(\"age\", df_spark[\"age\"].cast(IntegerType()))\n",
    "df_spark = df_spark.withColumn(\"visa_code\", df_spark[\"visa_code\"].cast(IntegerType()))\n",
    "df_spark = df_spark.withColumn(\"adm_num\", df_spark[\"adm_num\"].cast(IntegerType()))\n",
    "df_spark = df_spark.withColumn(\"arrival_date\",udf_datetime_from_sas(\"arrival_date\"))\n",
    "df_spark = df_spark.withColumn(\"departure_date\",udf_datetime_from_sas(\"departure_date\"))\n",
    "df_spark.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert text columns to integer in pandas dataframe\n",
    "df_visa[\"code\"] = pd.to_numeric(df_visa[\"code\"])\n",
    "df_mode[\"code\"] = pd.to_numeric(df_mode[\"code\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Remove Duplicated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of immigration rows: 2917199\n",
      "Removing duplicated rows\n",
      "Number of rows removed: 0\n"
     ]
    }
   ],
   "source": [
    "rows_count = df_spark.count()\n",
    "print(\"Number of immigration rows: {}\".format(rows_count))\n",
    "\n",
    "# removing duplicated rows\n",
    "print(\"Removing duplicated rows\")\n",
    "df_spark = df_spark.drop_duplicates()\n",
    "rows_count_current = df_spark.count()\n",
    "print(\"Number of rows removed: {}\".format(rows_count - rows_count_current))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Saving Data\n",
    "Saving data to parquet files and csv files.\n",
    "All files will be saved on AWS S3.\n",
    "\n",
    "**S3 Bucket: \n",
    "<br>\n",
    "s3a://udacity-capstone-2020-3/parquets/capstone_final**\n",
    "<br>\n",
    "**s3a://udacity-capstone-2020-3/csv_files/**\n",
    "\n",
    "**note**: A local copy of parquet files can be found under folder **/capstone** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write immigration data to parquet\n",
    "output_data = \"s3a://udacity-capstone-2020-3/parquets/\"\n",
    "df_spark.write.parquet(output_data + \"capstone_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write data to csv\n",
    "output_data = \"s3a://udacity-capstone-2020-3/\"\n",
    "fs = s3fs.S3FileSystem(key=os.environ['AWS_ACCESS_KEY_ID'], secret=os.environ['AWS_SECRET_ACCESS_KEY'])\n",
    "\n",
    "bytes_to_write = df_country.to_csv(header=None, index=None).encode()\n",
    "with fs.open(output_data + \"csv_files/countries.csv\", 'wb') as f:\n",
    "   f.write(bytes_to_write)\n",
    "\n",
    "bytes_to_write = df_state.to_csv(header=None, index=None).encode()\n",
    "with fs.open(output_data + \"csv_files/states.csv\", 'wb') as f:\n",
    "   f.write(bytes_to_write)\n",
    "\n",
    "bytes_to_write = df_port.to_csv(header=None, index=None).encode()\n",
    "with fs.open(output_data + \"csv_files/entry_ports.csv\", 'wb') as f:\n",
    "   f.write(bytes_to_write)\n",
    "\n",
    "bytes_to_write = df_airport.to_csv(header=None, index=None).encode()\n",
    "with fs.open(output_data + \"csv_files/airports.csv\", 'wb') as f:\n",
    "   f.write(bytes_to_write)\n",
    "\n",
    "bytes_to_write = df_country.to_csv(header=None, index=None).encode()\n",
    "with fs.open(output_data + \"csv_files/countries.csv\", 'wb') as f:\n",
    "   f.write(bytes_to_write)\n",
    "\n",
    "bytes_to_write = df_visa.to_csv(header=None, index=None).encode()\n",
    "with fs.open(output_data + \"csv_files/visa.csv\", 'wb') as f:\n",
    "   f.write(bytes_to_write)\n",
    "\n",
    "bytes_to_write = df_mode.to_csv(header=None, index=None).encode()\n",
    "with fs.open(output_data + \"csv_files/travel_modes.csv\", 'wb') as f:\n",
    "   f.write(bytes_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Model\n",
    "#### Conceptual Data Model and Data Dictionary\n",
    "\n",
    "The final data model of this project is designed as a Star schema, because it can be easily undestood and it also provide good query performance.\n",
    "<br>\n",
    "The data model contains the tables below:\n",
    "\n",
    "#### Staging tables:\n",
    "\n",
    "![title](staging.png)\n",
    "\n",
    "\n",
    "   * staging_i94\n",
    "       * cic_id - ID from data source table. Is was kept as primary for immigration table. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * year - immigration year. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * month - immigration month. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * country_code - country of origin. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * us_entry_port - entry port to US. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * arrival_date - date of arrival in US. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * travel_mode - mode of travel: Air, sea, land or not reported. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * us_state - state of stay in the US. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * departure_date - date of departure fom the US. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * age -  age of non-immigrant - \n",
    "           * **Source**: Immigration Data Source\n",
    "       * visa_code - visa category: Business, Pleasure or Student. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * gender - gender of non-immigrant. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * adm_num - admission number. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * visa_type - class of admission. \n",
    "           * **Source**: Immigration Data Source\n",
    "### ====================================================               \n",
    "   * staging_airports\n",
    "       * ident - airport code\n",
    "           * **Source**: Aiports data source  \n",
    "       * airport_type - airport type: heliport, small_airport, closed, seaplane_base, balloonport, medium_airport, large_airport\n",
    "           * **Source**: Aiports data source \n",
    "       * airport_name - name of airport\n",
    "           * **Source**: Aiports data source        \n",
    "       * elevation_ft - airport elevation\n",
    "           * **Source**: Aiports data source        \n",
    "       * continent - continent airport is located\n",
    "           * **Source**: Aiports data source       \n",
    "       * iso_country - country airport is located\n",
    "           * **Source**: Aiports data source \n",
    "       * iso_region - region(or state) airport is located\n",
    "           * **Source**: Aiports data source        \n",
    "       * municipality - city of airport\n",
    "           * **Source**: Aiports data source        \n",
    "       * gps_code - gps code\n",
    "            * **Source**: Aiports data source \n",
    "       * iata_code - three-letter geocode designating many airports and metropolitan areas around the world, defined by the International Air Transport Association (IATA). \n",
    "            * **Source**: Aiports data source      \n",
    "       * local_code - local code\n",
    "            * **Source**: Aiports data source       \n",
    "       * coordinates - airport coordinates\n",
    "            * **Source**: Aiports data source \n",
    "### ====================================================              \n",
    "   * staging_countries\n",
    "       * code - country code\n",
    "           * **Source**: Immigration data dictionary\n",
    "       * descrip - country name\n",
    "           * **Source**: Immigration data dictionary    \n",
    "### ====================================================             \n",
    "   * staging_states\n",
    "       * code - state code\n",
    "            * **Source**: Immigration data dictionary\n",
    "       * descrip - state name\n",
    "            * **Source**: Immigration data dictionary\n",
    "### ====================================================              \n",
    "   * staging_ports\n",
    "       * code - entry port code\n",
    "           * **Source**: Immigration data dictionary       \n",
    "       * descrip - entry port name\n",
    "           * **Source**: Immigration data dictionary       \n",
    "### ====================================================             \n",
    "   * staging_visa\n",
    "       * code - visa code\n",
    "           * **Source**: Immigration data dictionary       \n",
    "       * descrip - visa name\n",
    "           * **Source**: Immigration data dictionary       \n",
    "### ====================================================             \n",
    "   * staging_travel_mode\n",
    "       * code - travel mode code\n",
    "           * **Source**: Immigration data dictionary       \n",
    "       * descrip - travel mode name\n",
    "           * **Source**: Immigration data dictionary       \n",
    "       \n",
    "#### Dimension e Fact tables\n",
    "\n",
    "![title](dimension_fact.png)\n",
    "   * immigrations - fact table\n",
    "       * cic_id - ID from data source table. Is was kept as primary for immigration table. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * airport_id - airport code\n",
    "           * **Source**: Aiports data source   \n",
    "       * admission_id - admission number. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * arrival_date - date of arrival in US. \n",
    "           * **Source**: Immigration Data Source  \n",
    "       * departure_date - date of departure fom the US. \n",
    "           * **Source**: Immigration Data Source   \n",
    "       * travel_mode - mode of travel\n",
    "           * **Source**: Immigration data dictionary          \n",
    "       * year - immigration year. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * month - immigration month. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * country - country of origin. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * us_entry_port - entry port to US. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * gender - gender of non-immigrant. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * visa_code - visa category: Business, Pleasure or Student. \n",
    "           * **Source**: Immigration data dictionary \n",
    "       * visa_type - class of admission. \n",
    "           * **Source**: Immigration Data Source \n",
    "       * admission_state - state of stay in the US. \n",
    "           * **Source**: Immigration Data Source\n",
    "       * age -  age of non-immigrant\n",
    "           * **Source**: Immigration Data Source\n",
    "### ====================================================  \n",
    "   * airport - dimension table\n",
    "       * airport_id - airport code\n",
    "           * **Source**: Aiports data source  \n",
    "       * airport_type - airport type\n",
    "           * **Source**: Aiports data source \n",
    "       * airport_name - name of airport\n",
    "           * **Source**: Aiports data source        \n",
    "       * elevation_ft - airport elevation\n",
    "           * **Source**: Aiports data source        \n",
    "       * continent - continent airport is located\n",
    "           * **Source**: Aiports data source       \n",
    "       * iso_country - country airport is located\n",
    "           * **Source**: Aiports data source \n",
    "       * iso_region - region(or state) airport is located\n",
    "           * **Source**: Aiports data source        \n",
    "       * municipality - city of airport\n",
    "           * **Source**: Aiports data source        \n",
    "       * gps_code - gps code\n",
    "            * **Source**: Aiports data source \n",
    "       * iata_code - three-letter geocode designating many airports and metropolitan areas around the world, defined by the International Air Transport Association (IATA). \n",
    "            * **Source**: Aiports data source      \n",
    "       * local_code - local code\n",
    "            * **Source**: Aiports data source       \n",
    "       * coordinates - airport coordinates\n",
    "            * **Source**: Aiports data source  \n",
    "\n",
    "### ====================================================  \n",
    "   * time - dimension table\n",
    "\n",
    "       * start_time - time as timestamp\n",
    "            * **Source**: extracted from arrival_date and departure_date     \n",
    "       * hour - hour\n",
    "            * **Source**: calculated from start_time       \n",
    "       * day - day of month\n",
    "            * **Source**: calculated from start_time       \n",
    "       * week - week number\n",
    "            * **Source**: calculated from start_time       \n",
    "       * month - month\n",
    "            * **Source**: calculated from start_time       \n",
    "       * year - year\n",
    "            * **Source**: calculated from start_time       \n",
    "       * weekday - day of week\n",
    "            * **Source**: calculated from start_time       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Model creation\n",
    "\n",
    "All tables were created using the script **create_tables.sql**, which is located under folder **/airflow**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Pipelines\n",
    "\n",
    "The Data Pipeline was built with Apache Airflow, according to the diagram below:\n",
    "\n",
    "![title](airflow1.png)\n",
    "\n",
    "#### Data Pipeline Steps\n",
    "\n",
    "The data pipeline follow the steps below:\n",
    "\n",
    "1. Begin Execution\n",
    "    * This step starts the data pipeline\n",
    "2. Load staging tables\n",
    "    * This step loads data into all staging tables. This is made by the use of the command COPY\n",
    "3. Load immigration fact table\n",
    "    * This step loads data into the fact table immigration. This is made by the use of a SQL query\n",
    "4. Load dimension tables\n",
    "    * This step loads data into the fact table immigration. This is made by the use of SQL queries\n",
    "5. Run data quality checks\n",
    "    * This step checks data quality. More information is described in the next section\n",
    "6. Stop Execution\n",
    "    * This step ends the data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Quality Checks\n",
    "Data quality checks described below are performed during data pipeline:\n",
    "\n",
    " 1. Count check\n",
    "     * The size of tables from the final data model are checked in order to identify potential problems\n",
    " 2. Integrity constraints\n",
    "     * All tables from the final data model have a unique key (primary key constraint) in order to ensure data integrity and avoid duplicated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "All data pipeline source code can be found at folder **/airflow**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Tools:\n",
    "\n",
    "Python, Pandas, Spark and SQL were the main tools in this project to read, clean, process, and create tables.\n",
    "Considering that the amount of data per month and year provided by US National Tourism and Trade Office is is constantly growing, the architecture designed for this project supports scalability by the use of AWS tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Update\n",
    "Considering that data provided by US National Tourism and Trade Office is released once a month, the steps described in this project should run **monthly**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Increase Scenario\n",
    "\n",
    "Considering that this project already supports scalability by the use of AWS S3, AWS Redshift and Apache Airflow:\n",
    "  * **If the data was increased by 100x:**\n",
    "    * AWS S3 parquets could be partitioned by US state\n",
    "    * AWS EMR could be used for parallel processing    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data availability Scenario\n",
    "\n",
    " * **If the data populates a dashboard that must be updated on a daily basis by 7am every day:**\n",
    "   * The script could be changed to process only new data, instead of processing all input files everytime it is runned\n",
    "   * Another database (mirror) could be created in order to ensure that data will be always available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data concurrency Scenario\n",
    "   * **The database needed to be accessed by 100+ people**\n",
    "     * AWS Redshift configuration could be improved in order to increase performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Summary\n",
    "\n",
    "This project was implemented by the use of tools and techniques learned in the Data Enginner Nanodegree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
